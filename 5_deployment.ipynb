{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc5dNIkTmWxg"
      },
      "source": [
        "# Deployment\n",
        "Saving and evaluating the fine-tuned model."
      ],
      "id": "mc5dNIkTmWxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZbzGgBVmWxi"
      },
      "outputs": [],
      "source": [
        "# Save model and tokenizer\n",
        "model.save_pretrained(\"t5_finetuned_summary\")\n",
        "tokenizer.save_pretrained(\"t5_finetuned_summary\")"
      ],
      "id": "RZbzGgBVmWxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lkhYQ_imWxj"
      },
      "outputs": [],
      "source": [
        "# Load model and tokenizer (optional step for inference)\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5_finetuned_summary\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5_finetuned_summary\")"
      ],
      "id": "1lkhYQ_imWxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sisAJ6nmWxk"
      },
      "outputs": [],
      "source": [
        "# ROUGE Evaluation\n",
        "import evaluate\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "model.eval()\n",
        "generated_summaries = []\n",
        "true_summaries = []\n",
        "\n",
        "for i in range(100):\n",
        "    input_ids = small_dataset[i][\"input_ids\"].unsqueeze(0).to(model.device)\n",
        "    attention_mask = small_dataset[i][\"attention_mask\"].unsqueeze(0).to(model.device)\n",
        "    labels = small_dataset[i][\"labels\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
        "\n",
        "    generated = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    reference = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    generated_summaries.append(generated)\n",
        "    true_summaries.append(reference)\n",
        "\n",
        "results = rouge.compute(predictions=generated_summaries, references=true_summaries)\n",
        "print(results)"
      ],
      "id": "4sisAJ6nmWxk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}